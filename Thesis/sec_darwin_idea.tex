The basic idea of Darwin method was introduced in~ \cite{GMS09}. This idea will
be described in the following paragraph.

The uniqueness of the method comes from combining two distinct approaches ---
Interactive Multiobjective Optimisation (IMO, see~TODO) and Evolutionary
Multiobjective Optimization (EMO, see~TODO).

In the IMO paradigm we want to elicit Decision Maker (DM) preferences by
involving her in the process. This is done by systematic dialog with the
DM. Questions are being asked and the DM provides answers. Based on these
answers preference information is extracted. Algorithm can then use this
knowledge to produce solution better fitted to the Decision Maker
preferences. The IMO framework is presented on
fig.~\ref{fig:interactive-process}.

\begin{figure} 
  \begin{center}
    \begin{tikzpicture}[start chain, node distance=10mm,
        every join/.style={->}]

      
      \node (gen)     [on chain, join, roundrect]{
        \begin{tabular}{c}
          1. Generate set\\
          of possible solutions
      \end{tabular}};

      \node (ask) [on chain, join, roundrect] {
        \begin{tabular}{c}
          2. Ask the DM \\
          to indicate `good' ones
      \end{tabular}};

      \begin{scope}[start branch=store]
        \node (store) [roundrect,on chain=going below,join] {
          \begin{tabular}{c}
            3. Extract \\
            preference information
        \end{tabular}};

        \node (use) [roundrect,on chain=going left,join] {
          \begin{tabular}{c}
            4. Improve solution set
        \end{tabular}};
      \end{scope}

      
      \path (use) edge[->] (gen);
    \end{tikzpicture}
    \caption{Typical Interactive Multiobjective
      Optimisation process framework\label{fig:interactive-process}}
  \end{center} 
\end{figure} 

Rationale behind the interactive process is that the Decision Maker is
interested only in a small subset of preferred solutions or even in a single
most preferred one.

This process makes possible to gather preference information and then use this
information to construct better solutions. However this is just a framework,
details are left up to analyst. Especially one has to think how to extract and
store knowledge gathered on DM's answers and how to use this knowledge to
generate and provide solutions better fitted to Decision Maker's
preferences.

Human factor is another thing to consider. DM is a human being and thus her
behavior is constantly changing. The challenge here is to find what questions
should be asked, how often and how many intermediate solutions should be
presented to evaluate. 

Evolutionary Multiobjective Optimisation (EMO) provides a computational engine
for generating new, better solutions from existing ones. Better in sense of
objective function defined in the solution space. Most of the EMO methods are
approximating Pareto-optimal front by a set of solutions. So one solution is
better than the other if it Pareto-dominates it. In case of two equivalent
ones another factors have to be taken into account (for example crowding score
in NSGA2 [ref]). This is the case because if no preference information is
given all Pareto-optimal solutions has to be considered equivalent.



Most of past research on Evolutionary Multiobjective Optimization (EMO) at-
tempts to approximate the complete Pareto-optimal front by a set of well-
distributed representatives of Pareto-optimal solutions. The underlying reason-
ing is that in the absence of any preference information, all Pareto-optimal so-
lutions have to be considered equivalent.


From the point of view of EMO, involving the DM in an interactive procedure
allows to focus the search on the area of the Pareto front which is most
relevant to the DM. This, in turn, may allow to find preferred solutions
faster. In particular, in the case of many objectives, EMO has difficulties,
because the number of Pareto-optimal solutions becomes huge, and
Pareto-optimality is not sufficiently discriminative to guide the search into
better regions. Integrating userâ€™s preferences promises to alleviate these
problems, allowing to converge faster to the preferred region of the
Pareto-optimal front.
