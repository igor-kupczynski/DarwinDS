The basic idea of Darwin method was introduced in~ \cite{GMS09}. This idea will
be described in the following paragraph.

\subsection{Background}

The method combines two different approaches --- Interactive Multi-Objective
Optimisation (IMO, see~[inref]) and Evolutionary Multi-Objective Optimization
(EMO, see~[inref]).

In the IMO paradigm one wants to elicit decision maker's preferences by
involving his or her in the process. This is done by a systematic dialog with
the decision maker (the DM). Questions are being asked and the DM provides
answers. Based on these answers preference information is extracted. Algorithm
can then use the knowledge to produce solutions better fitted to his or her
preferences. The IMO framework is presented on
fig.~\ref{fig:interactive-process}.

\begin{figure} 
  \begin{center}
    \begin{tikzpicture}
      \matrix[row sep=10mm, column sep=10mm]{

        
        \node (gen)     [roundrect] {
          \begin{tabular}{c}
            1. Generate set\\
            of possible solutions
        \end{tabular}}; &

        \node (ask) [roundrect] {
          \begin{tabular}{c}
            2. Ask the DM \\
            to indicate `good' ones
        \end{tabular}}; \\

        \node (use) [roundrect] {
          \begin{tabular}{c}
            4. Improve solution set
        \end{tabular}}; &

        \node (store) [roundrect] {
          \begin{tabular}{c}
            3. Extract \\
            preference information
        \end{tabular}}; \\
      };
      \path (gen) edge[->] (ask);
      \path (ask) edge[->] (store);
      \path (store) edge[->] (use);
      \path (use) edge[->] (gen);
    \end{tikzpicture}
    \caption{Typical Interactive Multiobjective
      Optimisation process framework\label{fig:interactive-process}}
  \end{center} 
\end{figure} 

Rationale behind the interactive process is that the decision maker is
interested only in a small subset of preferred solutions or even in a single
most preferred one.

This process makes possible to gather preference information and then use this
information to construct a better solutions. However this is just a framework,
details are left up to the analyst. Especially one has to think how to extract
and store knowledge gathered on DM's answers and how to use this knowledge to
generate and provide solutions better fitted to decision maker's preferences.

Human factor is yet another thing to consider. The DM is a human being and
thus his or her behavior is constantly changing. The challenge here is to find
what questions should be asked, how often and how many intermediate solutions
should be presented to evaluate.

DARWIN is a realisation of the IMO process. It keeps generating solutions and
improving them based on the DM's feedback. It only asks the DM to mark
potentially good solutions, so only problem-domain knowledge is requires; its
user does not need to have an expert knowledge in the decision support field.

Evolutionary Multi-Objective Optimisation (EMO) provides a computational engine
for generating new, better solutions from existing ones. Better in sense of
objective function defined in the solution space. Most of the EMO methods are
approximating Pareto-optimal front by a set of solutions. So one solution is
better than the other if the former Pareto-dominates the latter. In case of
two equivalent ones another factors have to be taken into account (for example
crowding score in NSGA2 [ref]). This is the case because if no preference
information is given all Pareto-optimal solutions have to be considered
equivalent.

It seems natural to combine these two described approaches --- Interactive
Multi-Objective Optimisation and Evolutionary Multi-Objective
Optimisation. (TODO: maybe a note and a ref about combining these two
approaches). IMO is just a process framework but still needs an engine to
generate and improve solutions. EMO is such an engine. On the other hand for
EMO involving the decision maker in the procedure results in gathering
preference information. This information allows the procedure to focus on
specific region of Pareto-front --- the one most relevant to decision
maker. So IMO and EMO are complementing each other.

\begin{figure}
  \centering \includegraphics[width=1.2\textwidth]{img/pareto}
  \caption{Pareto-front and area preferred by the decision maker}
  \label{pareto}
\end{figure}

This is important because of the ``human factor''. If a number of solutions
becomes huge DM can not effectively analyze it and find the one that fits best
her preferences, thus Pareto-optimality is not sufficiently
discriminative. However guiding the search to preferred regions of the
solution space allows the method to coverage faster to good solutions. It is
shown on fig.~\ref{pareto}.

DARWIN uses EMO procedure to improve generated solutions based on the DM's
preferences.


\subsection{Uncertainty}

It is often the case that not all numbers and coefficients are precisely
known. It may be easier for the decision maker to formulate the
Multi-Objective Optimisation problem giving the problem coefficients in form
of intervals of possible values. For example instead of saying that product
price will equal 20 units one can say it will be in the $[19, 21]$
interval. In this situation the decision maker is often interested in finding
best robust solution --- that is good and possible in a large part of
uncertainty scenarios. DARWIN allows to give the coefficients in a form of
intervals.

\begin{figure}
  \centering \includegraphics[width=0.5\textwidth]{img/scenario}
  \caption{Scenario --- set of intervals fixed on specific values}
  \label{scenario}
\end{figure}

Set of all of the problem's coefficients given as intervals and fixed on one
of possible values will be called scenario of uncertainty (see
fig.~\ref{scenario}). If intervals are allowed it is impossible to calculate
exact value of problem's objectives for given solutions. To handle this case
all the considered solutions are evaluated over a~set of uncertainty
scenarios.

 Results of this evaluation are then aggregated to quantile space. The
 quantiles are points taken at regular intervals from the cumulative
 distribution of a random variable. Instead of presenting all of the results
 the method calculates meaningful quantiles of results distribution for each
 objective. For example percentiles (like $1\%, 25\%$ and $50\%$) can be
 chosen. Percentiles divide ordered data in 100 of equally-sized subsets ---
 $1\%$ percentile is the best of $1\%$ worst solutions or alternatively the
 worst of $99\%$ of best solutions.

Choice of these quantiles is connected with DM's attitude towards risk. If he
or she wants to avoid risk then his/her decision will be focused on quantiles
from the beginning of the distribution (e.g. $10\%$). On the other hand when
he or she is interested in best possible solution even if it is assisted with
risk then the quantiles from the of the distribution will be inspected
(e.g. $75\%$). 

In DARWIN DM's preferences are gathered and stored using DRSA methodology
(see~[inref]). Dominance-Based Rough Set Approach is a~framework for reasoning
about partially inconsistent preference data. DRSA already has a successful
applications in IMO area ([ref]).

DRSA will be applied in IMO process. After selecting ``good'' solutions
from the provided set the decision rules are induced to store the
preferences. These rules are given in form of \textit{``If ... then
  ...''}. Conditional part is a disjunction of conditions on attributes from
quantile space. These attributes are compared to a specific values, e.g.
$\text{profit}_{25\%} >= 100 \land \text{time}_{1\%} <= 10$. The consequent
part assigns a solution to a class (\textit{at least} or \textit{at most}),
e.g. Class \textit{at least} Good. So the whole rule would be If
$\text{profit}_{25\%} >= 100 \land \text{time}_{1\%} <= 10$ then Class
\textit{at least} Good.

\subsection{The algorithm}

DARWIN can operate on a Multi-Objective Optimisation (MMO) problems defined as
follows:

\begin{equation}
[ f_1(x), f_2(x), \dots, f_k(x) ] \rightarrow  \max
\end{equation}
subject to:
\begin{equation}
\begin{array}{l}
g_1(x) \geq b_1 \\
g_2(x) \geq b_2 \\
\dots \\
g_m(x) \geq b_m
\end{array}
\end{equation}

Where:
\begin{description}
\item $x = [x_1, x_2, \dots, x_n]$ is a vector of decision variables, called a
  solution;
\item $f_1(x), f_2(x), \dots, f_k(x)$ are objective functions,
  $f: x \rightarrow \mathbb{R}$;
\item $g_1(x), g_2(x), \dots, g_m(x)$ are constraint functions,
  $f: x \rightarrow \mathbb{R}$;
\item $b_1, b_2, \dots, b_m$ are real-valued right hand sides of the
  constraints.
\end{description}

It is possible to give some of the coefficients in objective functions or
constraints in form of intervals (thus modeling ignorance --- uncertainty
about real value of an coefficient). A vector of fixed values for each
interval is called \textit{scenario} of imprecision (see fig.~\ref{scenario}).

DARWIN is composed of two nested loops --- exterior and interior. The former
is a realisation of an interactive process and the latter is an EMO engine
dedicated to improve solutions based on the decision maker's preferences. This
is illustrated on a figure~\ref{fig:darwin-ext}.

\begin{figure} 
  \begin{center}
    \begin{tikzpicture}
      \matrix[row sep=10mm, column sep=10mm]{

        
        \node (gen)     [roundrect] {
          \begin{tabular}{c}
            (0) Generate:\\
            * solutions\\
            * scenarios
        \end{tabular}}; &

        \node (presentation) [greenrect] {
          \begin{tabular}{c}
            (1) Presentation \\
            of results
        \end{tabular}}; &

        \node (eval) [greenrect] {
          \begin{tabular}{c}
            (2) DM\\
            evaluation
        \end{tabular}}; \\

        \node (stop) [redrect] {
          \begin{tabular}{c}
            STOP
        \end{tabular}}; &

        \node (inner) [greenrect] {
          \begin{tabular}{c}
            (4) Evolutionary \\
            loop
        \end{tabular}}; &

        \node (rules) [greenrect] {
          \begin{tabular}{c}
            (3) Rules \\
            generation
        \end{tabular}}; \\
      };
      \path (gen) edge[->] (presentation);
      \path (presentation) edge[->] (eval);
      \path (eval) edge[->] (rules);
      \path (rules) edge[->] (inner);
      \path (inner) edge[->] (presentation);
      \path (presentation) edge[->] (stop);
    \end{tikzpicture}
    \caption{DARWIN states and transitions. Steps (1) - (4) are forming
      exterior loop and step (4) is the interior loop.\label{fig:darwin-ext}}
  \end{center} 
\end{figure}

\begin{algorithm}
\caption{DARWIN's exterior loop}\label{alg:extloop}
  \begin{algorithmic}[1]
    \State $X \gets$ \Call{GenerateSolutions}{} \label{algin:solgen}
    \State $S \gets$ \Call{GenerateScenarios}{} \label{algin:scengen}
    \Loop
    \ForAll{$x \in X, s \in S$} \label{algin:evstart}
    \State \Call{Evaluate}{$x, s$} 
    \EndFor{} \label{algin:evstop}
    \State $\text{satisfied} \gets$ \Call{PresentResults}{} \label{algin:dmshow}
    \If{$\text{satisfied}$}
    \State \textbf{stop}$\qed$ 
    \Else
    \State $X \gets$ \Call{AskToMarkGood}{$X$} \label{algin:dmmark}
    \EndIf
    \State rules $\gets$ \Call{InduceDecisionRules}{$X$} \label{algin:rules}
    \State $X \gets$ \Call{EmoProcedure}{rules} \Comment{the interior loop} \label{algin:intloop}
    \EndLoop{}
  \end{algorithmic}
\end{algorithm}


The exterior loop algorithm, corresponding to the IMO interactive process is
shown on alg.~\ref{alg:extloop}. More detailed description of each step
follows.

One has to generate a set of feasible solution to the MOO problem first. This
can be done using the Monte Carlo method. The method itself is not
knew. A~concept of statistical sampling became popular after inventing digital
computing machines (see~[ref]). This method can be described as random
sampling a domain of a problem. In most basic variant one can just pick a
solution at random and check if it is feasible. Unfortunately it could be
impossible unless the non-feasible space is only a small part of the
domain. Additional hints for the generator for example in form of analyst's
suggestions can be taken into account.

At this stage goals and constraints are allowed to contain intervals
corresponding to the uncertainty of a model of a set of scenarios needs to be
generated. Each one of these scenarios is a realisation of the problem with
fixed values of the intervals (see~[inref]). It is worth noting that if the
problem constraints are given in uncertain form --- that is containing
coefficients in form of intervals --- it could be impossible to determinate if
give solution is possible. If that is the case then lines \ref{algin:solgen}
and \ref{algin:scengen} should be inverted and feasibility of a solution set
should be checked on generated scenarios.

In lines \ref{algin:evstart} to \ref{algin:evstop} each solution if evaluated
on each scenario. Results of this evaluation phase are then gathered and
showed the decision maker in \ref{algin:dmshow}. The DM is a human being
though, so in order to get a valuable feedback one need to show the data in
aggregated form. The authors proposed a meaningful quantiles to be presented
(see~[inref]). For example $f^{1\%}_1(x), f^{25\%}_1(x), f^{50\%}_1(x),$
$\dots, f^{1\%}_k(x), f^{25\%}_k(x), f^{50\%}_k(x)$ for all $x \in X$.

If the DM finds solution in the set of presented ones satisfactory the problem
is solved and algorithm ends here. If not however he or she is asked to
indicated the ``good'' solutions in the set (line~\ref{algin:dmmark}).  Based
on this distinction method generates a set of decision rules
(line~\ref{algin:rules}). These rules are then passed to the interior loop
(line~\ref{algin:intloop}) where --- by using the EMO paradigm (see~[inref])
--- DARWIN performs search of the solution space. The search in driven towards
specific region based on the rules. Finally new solutions, better fitted to
DM's expectations are generated and the process starts over again.

Algorithm~\ref{alg:intloop} shows the interior loop of DARWIN method. This
loop is an EMO procedure [inref] guided by decision rules induced in exterior
loop on DM's selections.

\begin{algorithm}
\caption{DARWIN's interior loop}\label{alg:intloop}
  \begin{algorithmic}[1]
    \Procedure{EmoProcedure}{rules}
    \State $X \gets$ \Call{GenerateSolutions}{} \label{algin:solgen-int}
    \State $S \gets$ \Call{GenerateScenarios}{} \label{algin:scengen-int}
    \Loop \label{algin:evloop}
    \ForAll{$x \in X, s \in S$} \label{algin:evstart-int} \Comment{this loop
      calculates meaningful quantiles for each solution}
    \State \Call{Evaluate}{$x, s$}
    \EndFor{} \label{algin:evstop-int}
    \If{termination conditions fulfilled}
    \State \textbf{return} $X$
    \EndIf
    \State pScore $\gets$ \Call{CalculatePrimaryScore}{$X$} \label{algin:ps}
    \State sScore $\gets$ \Call{CalculateSecondaryScore}{$X$} \label{algin:ss}
    \State $X'$ $\gets$ \Call{RankSolutions}{$X$, pScore, sScore} \label{algin:rank}
    \State $P \gets$ \Call{SelectParents}{$X'$} \label{algin:select}
    \State $O \gets$ \Call{RecombineOffspring}{P} \label{algin:off}
    \State $O' \gets$ \Call{Mutate}{O} \label{algin:mut}
    \State $X \gets$ \Call{MergePopulations}{$X', O'$} \label{algin:merge}
    \EndLoop
    \EndProcedure{}
  \end{algorithmic}
\end{algorithm}

Procedure start by generating new set of feasible solutions and possible
scenarios in lines~\ref{algin:solgen-int}, \ref{algin:scengen-int}. Then in
line~\ref{algin:evloop} actual evolutionary optimisation starts.

Each solution is an individual. Solution set constitutes a
population. Iterations of a~loop defined in line~\ref{algin:evloop} marks 
generations of the population. Termination condition could be for example
a fixed number of iterations or a fixed amount of time.

In every generation first the population is evaluated and ranked. The process
starts with evaluation of each solution over every scenario
(\ref{algin:evstart-int} -- \ref{algin:evstop-int}). After the evaluation
meaningful quantiles are known for each solution. Then the procedure can
calculate a primary score for each of the individuals. The primary score is
computed as follows. Let:

\begin{description}
\item $\textit{rules}(x) = \{\textit{rule}_h \in \textit{rules} :$
$\textit{rule}_h$ is matched by solution $x\}$ \\
$\textit{rules}(x)$ is a set of rules ($\textit{rule}_h \in \textit{rules}$)
matched by solution $x \in X$. 

\item $X(\textit{rule}_h) = \{x \in X: x \text{is matching} \textit{rule}_h\}$
\\ For each $\textit{rule}_h \in rules: X(\textit{rule}_h)$ is a set of
solutions matching this rule.

\item $w(\textit{rule}_h) = (1 - \delta)^{\textit{card}(X(\textit{rule}_h))}$
  \\ Each rule ($\textit{rule}_h$) gets a~weight related to number of times it
  is matched by a~solution. $\delta$ is a~decay of rule weight. For example
  $\delta = 0.1$. This formula associates higher weight for rules matching
  lesser number of solutions --- this is an important property because it
  allows to maintain diversity with respect to rules.

\item $\textit{PrimaryScore}(x) = \sum_{\textit{rule}_h \in rules(x)}$
  $w(\textit{rule}_h)$ \\
Finally $\textit{PrimaryScore}(x)$ is a primary score of given solution ($x \in X$).
\end{description}

In case of a draw also a secondary score is considered for each solution. This
score is calculated in the same way as \textit{crowding distance} in
\textit{NSGA-II} method ([ref]). The difference lies in a fact, that this
score is calculated in a~quantile space instead of original objective space,
e.g. $f^{1\%}_1 \times f^{25\%}_1 \times f^{50\%}_1 \times \dots \times $
$f^{1\%}_k \times f^{25\%}_k \times f^{50\%}_k$. The procedure is shown in
alg.~\ref{alg:crowddist}.

\begin{algorithm}
  \caption{Procedure calculating crowding distance}\label{alg:crowddist}
  \begin{algorithmic}[1]
    \Procedure{CalculateCrowdingDistance}{$X$}
    \State $n \gets |X|$ \Comment{Number of solutions}
    \ForAll{$x \in X$} \Comment{Initialize}
    \State $\textit{distance}(x) = 0$
    \EndFor
    \ForAll{$o \in \textit{objectives}$}
    \State $X' \gets$ \Call{Sort}{$X, o$} \Comment{Sort solutions using value
      of $o$ objective}
    \State $\textit{distance}(X`(1)) \gets \infty$ \Comment{Boundary solutions
      get highest score possible}
    \State $\textit{distance}(X`(n)) \gets \infty$ \Comment{$X`(n)$ is the
      n-th element of the X` ordered set}
    \EndFor
    \For{$i \gets 2, n-2$} \Comment{$o(x), x \in X$ is a value of the objective $o$
    in the solution $s$}
    \State $\textit{distance}(X`(i)) \gets \textit{distance}(X`(i))$
    $+ [o(X`(i-1)) + o(X`(i-1))]$
    \EndFor
    \EndProcedure{}
  \end{algorithmic}
\end{algorithm}

In line~\ref{algin:select} parent selection is done. The process is a Monte
Carlo procedure and possibility of selecting a~solution $x \in X$ as parent
is:\\
$$Pr(x) = \left( \frac{|X|-\textit{rank}(x) + 1}{|X|} \right)^\gamma - \left( \frac{|X|-\textit{rank}(x)}{|X|} \right)^\gamma$$
where $\textit{rank}(x)$ is a rank of solution $x \in X$ in the ranking made
in line~\ref{algin:rank}. $\gamma \geq 1$ is a elitism coefficient. The higher
the $\gamma$ the bigger the probability of selecting high-ranked solution as
a~parent.

In line~\ref{algin:off} a new individual (a child) is created using two of the
parents chosen in previous step --- $a \in P, b \in P$. The child is obtained
by combining the parents together: $$z = \lambda a + (1 - \lambda) b$$
$\lambda$ is a random real-valued number; $0 \leq \lambda \leq 1$.


Mutation operator is applied to the offspring population. Probability of
mutation for a single individual is decreasing in successive generations and
can be calculated using the formula: $$Pr(t) = \epsilon (1 - \omega)^{t-1}$$
Where $t$ is a number of current iteration, $\omega$ - mutation decay rate,
$\epsilon$ - initial mutation probability. Suggested values are
$\omega = 0.1, \epsilon = 0.5$.
