The basic idea of Darwin method was introduced in~ \cite{GMS09}. This idea will
be described in the following paragraph.

\subsection{Background}

The method combines two different approaches --- Interactive Multiobjective
Optimisation (IMO, see~TODO) and Evolutionary Multiobjective Optimization
(EMO, see~TODO).

In the IMO paradigm we want to elicit Decision Maker (DM) preferences by
involving her in the process. This is done by systematic dialog with the
DM. Questions are being asked and the DM provides answers. Based on these
answers preference information is extracted. Algorithm can then use this
knowledge to produce solution better fitted to the Decision Maker
preferences. The IMO framework is presented on
fig.~\ref{fig:interactive-process}.

\begin{figure} 
  \begin{center}
    \begin{tikzpicture}
      \matrix[row sep=10mm, column sep=10mm]{

        
        \node (gen)     [roundrect] {
          \begin{tabular}{c}
            1. Generate set\\
            of possible solutions
        \end{tabular}}; &

        \node (ask) [roundrect] {
          \begin{tabular}{c}
            2. Ask the DM \\
            to indicate `good' ones
        \end{tabular}}; \\

        \node (use) [roundrect] {
          \begin{tabular}{c}
            4. Improve solution set
        \end{tabular}}; &

        \node (store) [roundrect] {
          \begin{tabular}{c}
            3. Extract \\
            preference information
        \end{tabular}}; \\
      };
      \path (gen) edge[->] (ask);
      \path (ask) edge[->] (store);
      \path (store) edge[->] (use);
      \path (use) edge[->] (gen);
    \end{tikzpicture}
    \caption{Typical Interactive Multiobjective
      Optimisation process framework\label{fig:interactive-process}}
  \end{center} 
\end{figure} 

Rationale behind the interactive process is that the Decision Maker is
interested only in a small subset of preferred solutions or even in a single
most preferred one.

This process makes possible to gather preference information and then use this
information to construct better solutions. However this is just a framework,
details are left up to analyst. Especially one has to think how to extract and
store knowledge gathered on DM's answers and how to use this knowledge to
generate and provide solutions better fitted to Decision Maker's
preferences.

Human factor is another thing to consider. DM is a human being and thus her
behavior is constantly changing. The challenge here is to find what questions
should be asked, how often and how many intermediate solutions should be
presented to evaluate. 

Evolutionary Multiobjective Optimisation (EMO) provides a computational engine
for generating new, better solutions from existing ones. Better in sense of
objective function defined in the solution space. Most of the EMO methods are
approximating Pareto-optimal front by a set of solutions. So one solution is
better than the other if the former Pareto-dominates the latter. In case of
two equivalent ones another factors have to be taken into account (for example
crowding score in NSGA2 [ref]). This is the case because if no preference
information is given all Pareto-optimal solutions have to be considered
equivalent.

It seems natural to combine these two approaches described --- Interactive
Multiobjective Optimisation and Evolutionary Multiobjective
Optimisation. (TODO: maybe a note and a ref about combining these two
approaches). IMO is just a process framework but still needs an engine to
generate and improve solutions. EMO is such an engine. On the other hand for
EMO involving the Decision Maker in the procedure results in gathering
preference information. This information allows the procedure to focus on
specific region of Pareto-front --- the one most relevant to decision maker.

\begin{figure}
  \centering \includegraphics[width=1.2\textwidth]{img/pareto}
  \caption{Pareto-front and area preferred by the Decision Maker}
  \label{pareto}
\end{figure}

This is important because of the ``human factor''. If a number of solution
becomes huge DM can not effectively analyze it and find the one that fits best
her preferences, thus Pareto-optimality is not sufficiently
discriminative. However guiding the search to preferred regions of the
solution space allows the method to coverage faster to good solutions. It is
shown on fig.~\ref{pareto}.


\subsection{Uncertainty}

TODO


\subsection{The algorithm}

DARWIN can operate on a Multi-Objective Optimisation (MMO) problems defined as
follows:

\begin{equation}
[ f_1(x), f_2(x), \dots, f_k(x) ] \rightarrow  \max
\end{equation}
subject to:
\begin{equation}
\begin{array}{l}
g_1(x) \geq b_1 \\
g_2(x) \geq b_2 \\
\dots \\
g_m(x) \geq b_m
\end{array}
\end{equation}

Where:
\begin{description}
\item $x = [x_1, x_2, \dots, x_n]$ is a vector of decision variables, called a
  solution;
\item $f_1(x), f_2(x), \dots, f_k(x)$ are objective functions,
  $f: x \rightarrow \mathbb{R}$;
\item $g_1(x), g_2(x), \dots, g_m(x)$ are constraint functions,
  $f: x \rightarrow \mathbb{R}$;
\item $b_1, b_2, \dots, b_m$ are real-valued right hand sides of the
  constraints.
\end{description}

\begin{figure}
  \centering \includegraphics[width=0.5\textwidth]{img/scenario}
  \caption{Scenario --- set of intervals fixed on specific values}
  \label{scenario}
\end{figure}

It is possible to give some of the coefficients in objective functions or
constraints in form of intervals (thus modeling ignorance --- uncertainty
about real value of an coefficient). A vector of fixed values for each
interval is called \textit{scenario} of imprecision (see fig.~\ref{scenario}).

DARWIN is composed of two nested loops --- exterior and interior. The former
is a realisation of an interactive process and the latter is an EMO engine
dedicated to improve solutions based on the Decision Maker preferences. This
is illustrated on figure~\ref{fig:darwin-ext}.

\begin{figure} 
  \begin{center}
    \begin{tikzpicture}
      \matrix[row sep=10mm, column sep=10mm]{

        
        \node (gen)     [roundrect] {
          \begin{tabular}{c}
            (0) Generate:\\
            * solutions\\
            * scenarios
        \end{tabular}}; &

        \node (presentation) [greenrect] {
          \begin{tabular}{c}
            (1) Presentation \\
            of results
        \end{tabular}}; &

        \node (eval) [greenrect] {
          \begin{tabular}{c}
            (2) DM\\
            evaluation
        \end{tabular}}; \\

        \node (stop) [redrect] {
          \begin{tabular}{c}
            STOP
        \end{tabular}}; &

        \node (inner) [greenrect] {
          \begin{tabular}{c}
            (4) Evolutionary \\
            loop
        \end{tabular}}; &

        \node (rules) [greenrect] {
          \begin{tabular}{c}
            (3) Rules \\
            generation
        \end{tabular}}; \\
      };
      \path (gen) edge[->] (presentation);
      \path (presentation) edge[->] (eval);
      \path (eval) edge[->] (rules);
      \path (rules) edge[->] (inner);
      \path (inner) edge[->] (presentation);
      \path (presentation) edge[->] (stop);
    \end{tikzpicture}
    \caption{DARWIN states and transitions. Steps (1) - (4) are forming
      exterior loop and step (4) is the interior loop.\label{fig:darwin-ext}}
  \end{center} 
\end{figure}

\begin{algorithm}
\caption{DARWIN's exterior loop}\label{alg:extloop}
  \begin{algorithmic}[1]
    \State $X \gets$ \Call{GenerateSolutions}{} \label{algin:solgen}
    \State $S \gets$ \Call{GenerateScenarios}{} \label{algin:scengen}
    \Loop
    \ForAll{$x \in X, s \in S$} \label{algin:evstart}
    \State \Call{Evaluate}{$x, s$} 
    \EndFor{} \label{algin:evstop}
    \State $\text{satisfied} \gets$ \Call{PresentResults}{} \label{algin:dmshow}
    \If{$\text{satisfied}$}
    \State \textbf{stop}$\qed$ 
    \Else
    \State $X \gets$ \Call{AskToMarkGood}{$X$} \label{algin:dmmark}
    \EndIf
    \State rules $\gets$ \Call{InduceDecisionRules}{$X$} \label{algin:rules}
    \State $X \gets$ \Call{EmoProcedure}{rules} \Comment{the interior loop} \label{algin:intloop}
    \EndLoop{}
  \end{algorithmic}
\end{algorithm}


The exterior loop algorithm, corresponding to the IMO interactive process is
shown on alg.~\ref{alg:extloop}. More detailed description of each step
follows.

One has to generate a set of feasible solution to the MOO problem first. This
can be done using the Monte Carlo method. The method itself is not
knew. A~concept of statistical sampling became popular after inventing digital
computing machines (see~[ref]). This method can be described as random
sampling a domain of a problem. In most basic variant one can just pick a
solution at random and check if it is feasible. Unfortunately it could be
impossible unless the non-feasible space is only a small part of the
domain. Additional hints for the generator for example in form of analyst's
suggestions can be taken into account.

At this stage goals and constraints are allowed to contain intervals
corresponding to the uncertainty of a model of a set of scenarios needs to be
generated. Each one of these scenarios is a realisation of the problem with
fixed values of the intervals (see~[inref]). It is worth noting that if the
problem constraints are given in uncertain form --- that is containing
coefficients in form of intervals --- it could be impossible to determinate if
give solution is possible. If that is the case then lines \ref{algin:solgen}
and \ref{algin:scengen} should be inverted and feasibility of a solution set
should be checked on generated scenarios.

In lines \ref{algin:evstart} to \ref{algin:evstop} each solution if evaluated
on each scenario. Results of this evaluation phase are then gathered and
showed the Decision Maker in \ref{algin:dmshow}. The DM is a human being
though, so in order to get a valuable feedback one need to show the data in
aggregated form. The authors proposed a meaningful quantiles to be presented
(see~[inref]). For example $f^{1\%}_1(x), f^{25\%}_1(x), f^{50\%}_1(x),$
$\dots, f^{1\%}_k(x), f^{25\%}_k(x), f^{50\%}_k(x)$ for all $x \in X$.

If the DM finds solution in the set of presented ones satisfactory the problem
is solved and algorithm ends here. If not however he or she is asked to
indicated the ``good'' solutions in the set (line~\ref{algin:dmmark}).  Based
on this distinction method generates a set of decision rules
(line~\ref{algin:rules}). These rules are then passed to the interior loop
(line~\ref{algin:intloop}) where --- by using the EMO paradigm (see~[inref])
--- DARWIN performs search of the solution space. The search in driven towards
specific region based on the rules. Finally new solutions, better fitted to
DM's expectations are generated and the process starts over again.

Algorithm~\ref{alg:intloop} shows the interior loop of DARWIN method. This
loop is an EMO procedure [inref] guided by decision rules induced in exterior
loop on DM's selections.

\begin{algorithm}
\caption{DARWIN's interior loop}\label{alg:intloop}
  \begin{algorithmic}[1]
    \Procedure{EmoProcedure}{rules}
    \State $X \gets$ \Call{GenerateSolutions}{} \label{algin:solgen-int}
    \State $S \gets$ \Call{GenerateScenarios}{} \label{algin:scengen-int}
    \Loop \label{algin:evloop}
    \ForAll{$x \in X, s \in S$} \label{algin:evstart-int} \Comment{this loop
      calculates meaningful quantiles for each solution}
    \State \Call{Evaluate}{$x, s$}
    \EndFor{} \label{algin:evstop-int}
    \If{termination conditions fulfilled}
    \State \textbf{return} $X$
    \EndIf
    \State pScore $\gets$ \Call{CalculatePrimaryScore}{$X$} \label{algin:ps}
    \State sScore $\gets$ \Call{CalculateSecondaryScore}{$X$} \label{algin:ss}
    \State $X'$ $\gets$ \Call{RankSolutions}{$X$, pScore, sScore} \label{algin:rank}
    \State $P \gets$ \Call{SelectParents}{$X'$} \label{algin:select}
    \State $O \gets$ \Call{RecombineOffspring}{P} \label{algin:off}
    \State $O' \gets$ \Call{Mutate}{O} \label{algin:mut}
    \State $X \gets$ \Call{MergePopulations}{$X', O'$} \label{algin:merge}
    \EndLoop
    \EndProcedure{}
  \end{algorithmic}
\end{algorithm}

Procedure start by generating new set of feasible solutions and possible
scenarios in lines~\ref{algin:solgen-int}, \ref{algin:scengen-int}. Then in
line~\ref{algin:evloop} actual evolutionary optimisation starts.

Each solution is an individual. Solution set constitutes a
population. Iterations of a~loop defined in line~\ref{algin:evloop} marks 
generations of the population.

In every generation first the population is evaluated and ranked. The process
starts with evaluation of each solution over every scenario
(\ref{algin:evstart-int} -- \ref{algin:evstop-int}). After the evaluation
meaningful quantiles are known for each solution. Then the procedure can
calculate a primary score for each of the individuals. The primary score is
computed as follows. Let:

\begin{description}
\item $\textit{rules}(x) = \{\textit{rule}_h \in \textit{rules} :$
$\textit{rule}_h$ is matched by solution $x\}$ \\
$\textit{rules}(x)$ is a set of rules ($\textit{rule}_h \in \textit{rules}$)
matched by solution $x \in X$. 

\item $X(\textit{rule}_h) = \{x \in X: x \text{is matching} \textit{rule}_h\}$
\\ For each $\textit{rule}_h \in rules: X(\textit{rule}_h)$ is a set of
solutions matching this rule.

\item $w(\textit{rule}_h) = (1 - \delta)^{\textit{card}(X(\textit{rule}_h))}$
  \\ Each rule ($\textit{rule}_h$) gets a~weight related to number of times it
  is matched by a~solution. $\delta$ is a~decay of rule weight. For example
  $\delta = 0.1$. This formula associates higher weight for rules matching
  lesser number of solutions --- this is an important property because it
  allows to maintain diversity with respect to rules.

\item $\textit{PrimaryScore}(x) = \sum_{\textit{rule}_h \in rules(x)}$
  $w(\textit{rule}_h)$ \\
Finally $\textit{PrimaryScore}(x)$ is a primary score of given solution ($x \in X$).
\end{description}

In case of a draw also a secondary score is considered for each solution. This
score is calculated in the same way as \textit{crowding distance} in
\textit{NSGA-II} method ([ref]). The difference lies in a fact, that this
score is calculated in a~quantile space instead of original objective space,
e.g. $f^{1\%}_1 \times f^{25\%}_1 \times f^{50\%}_1 \times \dots$
$\times f^{1\%}_k \times f^{25\%}_k \times f^{50\%}_k(x)$
