DARWIN is a new method and according to knowledge of the author and the
supervisor haven't been implemented before. Experiments are
designed to check if the method is working at all, what parameters are important
for the method and what should be their reasonable default values. To make
results repeatable the DM is mocked. Noise in his or her decisions is
simulated. Unless uncertainty is involved comparisons to exact optimal
solution are provided. In tests involving uncertainty results are compared to
supposed utility function optimisation. 

\section{The environment}

All tests were conducted on a personal computer with 64bit Intel
processor. RAM size on the machine is 3GB. 64bit Linux operating system was
used. The Java Virtual Machine was in version 1.6.0\_18 and Scala 2.8.0. JVM
was run with options \texttt{-Xms768m -Xmx768m} thus setting memory available
for application to 768MB. Tests were performed through CLI batch interface.

Test framework is available in order to automate the experiment process. All
experiments were repeated at least thirteen times. Data analysis and chart
generation was performed using an R environment [ref]. The framework is a
combination of Python [ref] and Bash [ref] code communicating with main DARWIN
code and with the modules written in R.

\section{The Decision Maker}

Experiments were repeated many times. In order to make it possible it was
essential to mock the DM. This was also done to assure repeatable process
across the test runs.

In the DARWIN method interaction with decision maker occurs by showing him or
her a list of generated solutions (usually 30) and asking him or her to
indicate few ``good'' ones.

To mock the DM one need to simulate his or her selections. It is assumed that
the decision maker acts according to a utility functions he or her has in
mind. This function will be called the supposed utility function.

In the mocking process algorithm sorts the received solutions list according
to this supposed utility function. Then it selects three (usually three,
however this can be configured) solutions with the highest supposed utility.

Unfortunately real decision maker, being a human isn't a predictive and
repeatable as the described process. In the section [inref] results of
introducing noise to DM's decisions are presented.

In the following problems the supposed utility function is also defined.

\section{Problem selection}

Area of interest for Multi-Objective Optimisation is huge and consists of many
potential problems to be solved. There are multi-criteria versions of
classical problems, like minimal spanning tree~[ref], traveling salesman
problem (TSP)~[ref] or knapsack problem~[ref] as well as artificially
generated ones --- like the DTLZ problems [ref]. Some of them are interesting
because of their real-life applications while the other are good for
experimenting and testing purposes.

It is worth noting that the ordinary single-criterion versions of the problems
can be easy to solve. However in multi-criteria setting one has to infer the
decision maker preferences and approximate supposed utility function
correctly. The challenge here is not to build the best optimisation algorithm
for all the problems (what is impossible according to no-free-lunch theorem
[ref]) but rather a framework for preference information extraction.

Introducing uncertainty model as intervals is a new concept. For this reason
the uncertainty was added to the problems described above.

The experiments were performed using following problems:
\begin{description}
  \item{\textbf{Two-criteria binary knapsack problem}}
    \begin{align*}
      & \bar{x} = [x_1, x_2, \dots, x_{300}]  \\
      & x_i \in \{0, 1\};  \hspace{0.5cm} i = 1, 2, \dots, 300 \\
      & \textit{max}\text{ value$_1$:} \hspace{0.2cm} \bar{a_1} \cdot \bar{x} \\
      & \textit{max}\text{ value$_2$:} \hspace{0.2cm} \bar{a_2} \cdot \bar{x} \\
      & \textit{subject to:} \\
      & \hspace{0.5cm} \text{weight:} \hspace{0.2cm} \bar{w} \cdot \bar{x}
      \leq b \\
      & \textit{(max) supposed utility:} \\
      & \hspace{0.5cm} 1*\text{value}_1 + 2*\text{value}_2
    \end{align*}
    
    Where $\bar{x}$ is a vector of items to be chosen. The problem is binary,
    so each $x_i \in \bar{x}$ can be either selected ($x_i = 1$) or not($x_i
    = 0$). There are two criteria: value$_1$ and value$_2$. Each one is a sum
    of items multiplied with associated weights (vector $\bar{a_1}$ and
    $\bar{a_2}$).

    Knapsack constraint is given. One can choose items up to a certain weight
    ($b$). There is a vector of weights associated with each item
    ($\bar{w}$). The limit is defined that it is possible to choose about
    $2/3$ of the items.

    Weights ($\bar{a_1}, \bar{a_2}, \bar{w}$) are uniformly distributed
    vectors of values in $[0,10)$ interval.


  \item{\textbf{Two-criteria continuous knapsack problem}}
    \begin{align*}
      & \bar{x} = [x_1, x_2, \dots, x_{300}]  \\
      & x_i \in [0, 1);  \hspace{0.5cm} i = 1, 2, \dots, 300 \\
      & \textit{max}\text{ value$_1$:} \hspace{0.2cm} \bar{a_1} \cdot \bar{x} \\
      & \textit{max}\text{ value$_2$:} \hspace{0.2cm} \bar{a_2} \cdot \bar{x} \\
      & \textit{subject to:} \\
      & \hspace{0.5cm} \text{weight:}  \hspace{0.2cm} \bar{w} \cdot \bar{x}
        \leq b \\
      & \textit{(max) supposed utility:} \\
      & \hspace{0.5cm} 3 * \text{value}_1 - 1 * \text{value}_2
    \end{align*}

    Continuous version of the knapsack problem. Description given for the
    binary version also applies here. The only difference is that now item can
    be partially selected ($\forall_{x_i \in \bar{x}} x_i \in [0, 1)$). 

  \item{\textbf{Three-criteria binary knapsack problem}}
    \begin{align*}
      & \bar{x} = [x_1, x_2, \dots, x_{300}]  \\
      & x_i \in \{0, 1\};  \hspace{0.5cm} i = 1, 2, \dots, 300 \\
      & \textit{max}\text{ value$_1$:} \hspace{0.2cm} \bar{a_1} \cdot \bar{x} \\
      & \textit{max}\text{ value$_2$:} \hspace{0.2cm} \bar{a_2} \cdot \bar{x} \\
      & \textit{max}\text{ value$_3$:} \hspace{0.2cm} \bar{a_3} \cdot \bar{x} \\
      & \textit{subject to:} \\
      & \hspace{0.5cm} \text{weight:} \hspace{0.2cm} \bar{w} \cdot \bar{x}
      \leq b \\
      & \textit{(max) supposed utility:} \\
      & \hspace{0.5cm} 1 * \text{value}_1 - 1 * \text{value}_2 + 2 * \text{value}_22
    \end{align*}

    Two-criteria problems can be easily visualised and analysed, however in
    real-life applications there is often a need for three and more
    criteria. There is a moving from two to multiple, so it is worth comparing
    the results achieved on the three-criteria knapsack problem with its
    two-criteria counterpart. 

  \item{\textbf{Three-criteria DTLZ problem generated using constraint surface
    approach}}
    \begin{align*}
      & \textit{min}\text{ f$_1$:} \hspace{0.2cm} x_1 \\
      & \textit{min}\text{ f$_2$:} \hspace{0.2cm} x_2 \\
      & \textit{min}\text{ f$_3$:} \hspace{0.2cm} x_3 \\
      & \textit{subject to:} \\
      & \hspace{0.5cm} 0 \le x_i \le 1, \hspace{0.2cm} i = 1, 2, 3 \\
      & \hspace{0.5cm} -x_1 + x_2 + 0.6 \ge 0 \\
      & \hspace{0.5cm} x_1 + x_3 - 0.5 \ge 0 \\
      & \hspace{0.5cm} x_1 + x_2 + x_3 - 1.1 \ge 0 \\
      & \textit{(max) supposed utility:} \\
      & \hspace{0.5cm} -1 * \text{f}_1 - 2 * \text{f}_2 - 1 * \text{f}_3
    \end{align*}

    This problem consists of three simple linear criteria. The solution space
    is three dimensional cube bounded by the $0 \le x_i \le 1$ constraint. To
    make the problem more interesting parts of the solution space are being
    cut off by additional constraints.

    This problem was build according to constraint surface approach presented
    in~[ref].

  \item{\textbf{Two-criteria robust mix problem}}
    \begin{align*}
      & \textit{max}\text{ profit:} \hspace{0.2cm} p_A \text{min}(x_A, d_A)
      + p_B \text{min}(x_B, d_B) +  p_C \text{min}(x_C, d_C) \\
      & \hspace{1cm} - (r^1_Ax_A + r^1_Bx_B + r^1_Cx_C) p^1_R
      - (r^2_Ax_A + r^2_Bx_B + r^2_Cx_C) p^2_R\\
      & \textit{min}\text{ time:} \hspace{0.2cm} t_Ax_A + t_Bx_B + t_Cx_C \\
      & \textit{where:} \\
      & \hspace{0.5cm} p_A \in [20, 24], p_B \in [30, 36], p_C \in [25, 30] \\
      & \hspace{0.5cm} d_A \in [10, 12], d_B \in [20, 24], d_C \in [10, 12] \\
      & \hspace{0.5cm} r^1_A \in [1, 1.2], r^1_B \in [2, 2.4], r^1_C \in [0.75, 0.9] \\ 
      & \hspace{0.5cm} r^2_A \in [0,5, 0.6], r^2_B \in [1, 1.2], r^2_C \in [0.5, 0.6] \\ 
      & \hspace{0.5cm} p^1_R \in [6, 7.2], p^2_R \in [9, 9.6] \\
      & \hspace{0.5cm} t_A \in [5, 6], t_B \in [8, 9.6], t_C \in [10, 12] \\ 
      & \textit{subject to:} \\
      & \hspace{0.5cm} 0 \le x_A \le 12 \\
      & \hspace{0.5cm} 0 \le x_B \le 24 \\
      & \hspace{0.5cm} 0 \le x_C \le 12 \\
      & \textit{(max) supposed utility:} \\
      & \hspace{0.5cm} \text{profit}^{1\%} + 3 * \text{profit}^{25\%}
      + 2 * \text{profit}^{50\%} - \text{time}^{1\%}
      - 3 * \text{time}^{25\%} - 2 * \text{time}^{50\%} 
    \end{align*}
    
    
    The problem was described in a presentation given on ... ([ref])
    describing the DARWIN method. It contains a lot of coefficients given in
    form of intervals. For readability's sake they were named and defined
    below the criteria.

    The goal is to decide quantity of each product ($A, B, C$) to be
    produced. One wants to maximise the profit and minimised the total time it
    takes to produce the products. $p_i$ is the price of a product $i \in \{A,
    B, C\}$ on the market. There is also maximal demand the market can consume
    ($d_i$). Each product consists of two raw materials --- $r_1$ and
    $r_2$. Quantity needed to produce $i$-th product is defined ($r^1_i,
    r^2_i$) as well as the product price ($p^1_R, p^2_R$). Finally it takes
    time to produce a given product --- $t_A, t_B, t_C$.

    Coefficients are given in form of intervals, so each solution has to be
    evaluated on many scenarios of uncertainty. This is why no exact values
    are given in the supposed utility function. Percentiles are given instead
    (see~[inref]). $\text{goal}^{25\%}$ means the best solution of the worst
    $25\%$ of them.

  \item{\textbf{Tree-criteria robust DTLZ7 problem}}

  \item{\textbf{Four-criteria robust DTLZ1 problem}}

  \item{\textbf{Ten-criteria robust DTLZ1 problem}}

\end{description}

\section{No uncertainty}

\section{The importance of parameters}

\section{Noise in the DM's decisions}

\section{Uncertainty}

\section{Conclusions}

